# ===================== 1. åŸºç¡€è®¾ç½® =====================
import numpy as np
if not hasattr(np, 'bool'):
    np.bool = np.bool_
    np.int = np.int_

import emcee
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
import re
from warnings import filterwarnings

filterwarnings('ignore')

# ç»˜å›¾é…ç½®
import platform
system_name = platform.system()
font_list = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['font.sans-serif'] = font_list
plt.rcParams['axes.unicode_minus'] = False
np.random.seed(2026)

# ===================== 2. å¢å¼ºç‰ˆæ•°æ®è¯»å–ï¼ˆæ ¸å¿ƒæ”¹è¿›ï¼‰ =====================
def read_and_process_data():
    file_path = "2026_MCM_Problem_C_Data.csv"
    # å°è¯•å¤šç§ç¼–ç è¯»å–
    try:
        raw_df = pd.read_csv(file_path, encoding='utf-8-sig')
    except:
        raw_df = pd.read_csv(file_path, encoding='latin1')
    
    # 1. åŸºç¡€æ¸…æ´—
    raw_df.columns = [c.lower().strip() for c in raw_df.columns]
    
    # 2. æå–è¯„å§”åˆ†æ•° (Judge Scores)
    # æˆ‘ä»¬éœ€è¦æŠŠå®½è¡¨(Wide)è½¬æ¢ä¸ºé•¿è¡¨(Long)ï¼Œå¹¶ä¿ç•™æ¯ä¸€å‘¨çš„è¯„å§”åˆ†
    # å‡è®¾åˆ—åæ ¼å¼ç±»ä¼¼: "week1_judge1", "week 1 judge 1" ç­‰
    
    # å…ˆæ„å»ºåŸºç¡€çš„é•¿è¡¨éª¨æ¶
    base_cols = ['season', 'placement', 'celebrity_age_during_season', 
                 'celebrity_homecountry/region', 'celebrity_industry', 'results']
    # å®¹é”™ï¼šå¦‚æœæ‰¾ä¸åˆ°åˆ—åï¼Œç”¨ç›¸è¿‘çš„
    available_cols = [c for c in base_cols if c in raw_df.columns]
    
    # è‡ªåŠ¨è¯†åˆ«å…±æœ‰å¤šå°‘å‘¨
    week_cols = [c for c in raw_df.columns if 'week' in c and 'judge' in c]
    max_week = 10 # é»˜è®¤
    if week_cols:
        weeks = [int(re.findall(r'week\s*(\d+)', c)[0]) for c in week_cols if re.findall(r'week\s*(\d+)', c)]
        if weeks: max_week = max(weeks)

    long_data = []
    
    for idx, row in raw_df.iterrows():
        season = row.get('season', 1) # é»˜è®¤1
        # å¾ˆå¤šæ•°æ®æ²¡æœ‰æ˜¾å¼çš„seasonåˆ—ï¼Œéœ€è¦æŒ‰è¡Œæ•°æ¨æ–­ï¼Œæˆ–è€…å‡è®¾æ–‡ä»¶é‡Œæœ‰
        # è¿™é‡Œä¸ºäº†ç¨³å¥ï¼Œå¦‚æœCSVé‡Œæ²¡seasonï¼Œæˆ‘ä»¬æŒ‰è¡Œå·åˆ†å—ï¼ˆæ¯è¡Œä¸€ä¸ªé€‰æ‰‹ï¼‰
        # *æ³¨æ„*ï¼šåŸé¢˜æ•°æ®ç»“æ„é€šå¸¸æ˜¯ä¸€è¡Œä¸€ä¸ªé€‰æ‰‹ã€‚
        
        final_rank = row.get('placement', np.nan)
        if pd.isna(final_rank): continue
        if str(final_rank) == 'nan': continue
        
        # å°è¯•è½¬æ¢Rank
        try:
            final_rank = int(str(final_rank).replace('Place', '').strip())
        except:
            final_rank = 15 # é»˜è®¤ä½æ’å
            
        # æå–ç‰¹å¾
        age = row.get('celebrity_age_during_season', 30)
        country = row.get('celebrity_homecountry/region', 'USA')
        industry = row.get('celebrity_industry', 'Actor')
        is_eliminated_season = 0 # æ ‡è®°æ•´å­£æ˜¯å¦è¢«æ·˜æ±°ï¼ˆé€šå¸¸éƒ½æ˜¯ï¼‰
        
        # éå†æ¯ä¸€å‘¨æå–è¯„å§”åˆ†
        for w in range(1, max_week + 1):
            # æŸ¥æ‰¾å½“å‘¨çš„æ‰€æœ‰è¯„å§”åˆ†
            # åŒ¹é…é€»è¾‘ï¼šåŒ…å« 'weekX' ä¸”åŒ…å« 'judge' çš„åˆ—
            # æˆ–è€…æ˜¯ 'weekX_score'
            score_sum = 0
            count = 0
            
            # æ­£åˆ™åŒ¹é…è¯¥å‘¨çš„æ‰€æœ‰åˆ†æ•°åˆ—
            pat = re.compile(f"week\s?{w}[^0-9]") 
            
            w_cols = [c for c in raw_df.columns if str(w) in c and ('judge' in c or 'score' in c)]
            
            current_week_scores = []
            for c in w_cols:
                val = row[c]
                try:
                    val = float(val)
                    if not pd.isna(val) and val > 0:
                        current_week_scores.append(val)
                except:
                    pass
            
            if len(current_week_scores) > 0:
                judge_avg = np.mean(current_week_scores)
                # å½’ä¸€åŒ–åˆ° 0-10 æˆ– 0-30
                judge_total = np.sum(current_week_scores)
            else:
                judge_total = 0 # è¯´æ˜æ²¡å‚åŠ è¿™ä¸€å‘¨ï¼Œæˆ–è€…è¢«æ·˜æ±°äº†
            
            # å¦‚æœåˆ†æ•°æ˜¯0ï¼Œä¸”ä¸æ˜¯ç¬¬ä¸€å‘¨ï¼Œé€šå¸¸æ„å‘³ç€å·²ç»è¢«æ·˜æ±°äº†
            if w > 1 and judge_total == 0:
                continue # ä¸æ·»åŠ è¿™ä¸€è¡Œ
            
            # ç»“æœæ ‡ç­¾ (Actual Eliminate)
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå¦‚æœæ˜¯é€‰æ‰‹å‚åŠ çš„æœ€åä¸€å‘¨ï¼ˆä¸”ä¸æ˜¯å†³èµ›ï¼‰ï¼Œåˆ™ä¸ºæ·˜æ±°
            # å®é™…ä¸Šå¾ˆéš¾ç²¾ç¡®å¯¹åº”å“ªå‘¨æ·˜æ±°ï¼Œæˆ‘ä»¬ç”¨ "Final Rank" å€’æ¨
            # ç®€å•çš„é€»è¾‘ï¼šæ’åè¶Šé å(æ•°å€¼å¤§)ï¼Œè¶Šæ—©æ·˜æ±°ã€‚
            # æš‚æ—¶å…ˆå…¨éƒ¨æ ‡è®°ä¸º0ï¼Œåé¢ç»Ÿä¸€è®¡ç®—
            
            long_data.append({
                'player_id': f"S{int(season):02d}-P{idx:03d}",
                'season': int(season),
                'week': w,
                'final_rank': final_rank,
                'judge_score': judge_total,
                'age': age,
                'country': country,
                'industry': industry
            })
            
    df = pd.DataFrame(long_data)
    
    # å¡«å……ï¼šå¤„ç† Age ç¼ºå¤±
    df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(35)
    
    # ç”Ÿæˆ "æœ¬å‘¨æ˜¯å¦æ·˜æ±°" çš„æ ‡ç­¾
    # é€»è¾‘ï¼šå¯¹äºæ¯ä¸ªèµ›å­£ï¼Œè®¡ç®—æ¯å‘¨çš„äººæ•°ã€‚äººæ•°å˜å°‘çš„æ—¶åˆ»ï¼Œå°±æ˜¯æœ‰äººæ·˜æ±°ã€‚
    # ç®€åŒ–ç‰ˆé€»è¾‘ï¼šæ ¹æ® final_rank å’Œ week çš„å…³ç³»ã€‚
    # å‡è®¾ï¼šæ€»äººæ•° Nã€‚ ç¬¬1åå‚åŠ äº†æ‰€æœ‰å‘¨ã€‚ ç¬¬Nååªå‚åŠ äº†ç¬¬1å‘¨ã€‚
    # æˆ‘ä»¬ç”¨ä¸€ç§ç»Ÿè®¡å­¦æ–¹æ³•ï¼šå¯¹äºåŒä¸€èµ›å­£åŒä¸€å‘¨ï¼Œ
    # æ ‡è®°ï¼šActual_Eliminate = 1 if (æœ¬é€‰æ‰‹æ˜¯è¯¥å‘¨ final_rank å€¼æœ€å¤§çš„é‚£ä¸ª)
    df['actual_eliminate'] = 0
    for s in df['season'].unique():
        for w in df[df['season']==s]['week'].unique():
            mask = (df['season']==s) & (df['week']==w)
            sub = df[mask]
            if len(sub) > 1:
                # æ‰¾åˆ°æœ¬å‘¨ä»åœ¨å‚èµ›çš„é€‰æ‰‹ä¸­ï¼Œæœ€ç»ˆæ’åæœ€å·®(æ•°å€¼æœ€å¤§)çš„äºº
                # è¿™æ˜¯ä¸€ä¸ªåˆç†çš„ä»£ç†å˜é‡(Proxy)
                max_rank = sub['final_rank'].max()
                # è¿˜è¦ç¡®ä¿ä»–æ²¡æœ‰å‚åŠ ä¸‹ä¸€å‘¨
                target_ids = sub[sub['final_rank'] == max_rank]['player_id'].values
                
                # æ£€æŸ¥è¿™äº›äººæ˜¯å¦æœ‰ä¸‹ä¸€å‘¨çš„æ•°æ®
                next_week_mask = (df['season']==s) & (df['week']==w+1) & (df['player_id'].isin(target_ids))
                if not df[next_week_mask].shape[0] > 0:
                    df.loc[mask & (df['final_rank'] == max_rank), 'actual_eliminate'] = 1

    return df

print("æ­£åœ¨è§£æå¹¶é‡æ„æ•°æ®ï¼ˆåŒ…å«è¯„å§”åˆ†æ•°æå–ï¼‰...")
df = read_and_process_data()
print(f"æ•°æ®é‡æ„å®Œæˆï¼Œæ ·æœ¬æ•°: {len(df)}")
# è¿‡æ»¤æ‰åˆ†æ•°å¼‚å¸¸ä½çš„è¡Œï¼ˆå¯èƒ½æ˜¯æœªå‚èµ›ï¼‰
df = df[df['judge_score'] > 0]

# ===================== 3. ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹æ‹†åˆ† =====================
def prepare_features(df):
    # 1. å¯¹è¯„å§”åˆ†æ•°è¿›è¡Œèµ›å­£å†…æ ‡å‡†åŒ–ï¼ˆæ¶ˆé™¤ä¸åŒèµ›å­£åˆ†åˆ¶ä¸åŒå¸¦æ¥çš„å½±å“ï¼‰
    df['judge_score_std'] = df.groupby(['season', 'week'])['judge_score'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-5)
    )
    
    # 2. ç¼–ç äººå£ç»Ÿè®¡å­¦ç‰¹å¾
    encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
    cat_features = ['industry'] # å›½å®¶å¤ªæ‚ï¼Œå…ˆåªç”¨è¡Œä¸š
    X_cat = encoder.fit_transform(df[cat_features])
    
    # 3. è¿ç»­ç‰¹å¾
    scaler = StandardScaler()
    X_num = scaler.fit_transform(df[['age']])
    
    # 4. åˆå¹¶ X
    # æ³¨æ„ï¼šæˆ‘ä»¬è¿™é‡Œä¸æŠŠ judge_score æ”¾å…¥ X æ¥é¢„æµ‹ fan_vote
    # å› ä¸ºæˆ‘ä»¬å‡è®¾ Fan Vote æ˜¯ç”±"äºº"å†³å®šçš„ï¼Œè€Œä¸æ˜¯ç”±"è¯„å§”åˆ†"å†³å®šçš„
    # ä½†æˆ‘ä»¬å¯ä»¥åŠ å…¥ 'judge_score_std' ä½œä¸ºåå˜é‡ï¼Œå› ä¸ºç²‰ä¸å®¹æ˜“è·Ÿé£
    X_final = np.hstack([np.ones((len(df), 1)), X_cat, X_num, df[['judge_score_std']].values])
    
    feature_names = ['Intercept'] + list(encoder.get_feature_names_out()) + ['Age', 'Judge_Influence']
    
    return df, X_final, feature_names

df, X_all, feat_names = prepare_features(df)

# ===================== 4. è´å¶æ–¯æ¨¡å‹ (Latent Fan Preference) =====================
# æ ¸å¿ƒæ€æƒ³ï¼šResult ~ Judge + Fan
# æˆ‘ä»¬å·²çŸ¥ Result (Survived=1, Elim=0) å’Œ Judgeã€‚
# æˆ‘ä»¬ç”¨ Logit æ¨¡å‹ï¼š P(Survival) = Sigmoid( alpha * Judge + beta * X_fan )
# è¿™é‡Œçš„ beta * X_fan å°±æ˜¯æˆ‘ä»¬è¦å­¦çš„ç²‰ä¸åå¥½ã€‚

def run_better_mcmc(X, y_elim, model_label):
    # è¿™é‡Œçš„ y_elim æ˜¯ "æ˜¯å¦è¢«æ·˜æ±°"ã€‚1=æ·˜æ±°ï¼Œ0=æ™‹çº§
    # é€»è¾‘ï¼šScore = X * theta
    # P(æ·˜æ±°) = Sigmoid(Score) 
    # *æ³¨æ„*ï¼šè¿™æ˜¯åå‘çš„ï¼Œåˆ†æ•°è¶Šä½è¶Šå®¹æ˜“æ·˜æ±°ã€‚
    # æ‰€ä»¥æˆ‘ä»¬å®šä¹‰ Latent Ability = X * theta
    # P(Elim) = 1 - Sigmoid(Ability)
    
    print(f"ğŸš€ æ­£åœ¨è®­ç»ƒ {model_label} (N={len(y_elim)})...")
    
    n_dim = X.shape[1]
    
    def log_lik(theta, x, y):
        # é€»è¾‘å›å½’ä¼¼ç„¶
        logits = np.dot(x, theta) 
        # y=1 (Eliminated) æ„å‘³ç€ Ability ä½ã€‚
        # æˆ‘ä»¬è®© theta ä»£è¡¨ "ç”Ÿå­˜èƒ½åŠ›" (Popularity)
        # é‚£ä¹ˆ P(Elim) = 1 / (1 + exp(logits))  (å½“logitså¾ˆå¤§æ—¶ï¼ŒP_elimå¾ˆå°)
        # log P(y=1) = -log(1 + exp(logits)) = log_sig(-logits)
        # log P(y=0) = log(1 - 1/(1+exp)) = log(exp/(1+exp)) = logits - log(1+exp)
        
        # ç®€å•çš„æ•°å€¼ç¨³å®šå†™æ³•:
        # P(y=0|x) = sigmoid(logits) -> æ™‹çº§æ¦‚ç‡
        # P(y=1|x) = 1 - sigmoid(logits) -> æ·˜æ±°æ¦‚ç‡
        
        # æˆ‘ä»¬çš„ y æ˜¯ actual_eliminate (1=æ·˜æ±°)
        # æ‰€ä»¥æˆ‘ä»¬æœ€å¤§åŒ–: y*log(1-p) + (1-y)*log(p)
        # å…¶ä¸­ p = sigmoid(logits)
        
        p = 1.0 / (1.0 + np.exp(-logits))
        epsilon = 1e-6
        p = np.clip(p, epsilon, 1-epsilon)
        
        # å¦‚æœ y=1 (æ·˜æ±°), æˆ‘ä»¬å¸Œæœ› p (æ™‹çº§ç‡) ä½ -> log(1-p)
        # å¦‚æœ y=0 (æ™‹çº§), æˆ‘ä»¬å¸Œæœ› p (æ™‹çº§ç‡) é«˜ -> log(p)
        ll = np.sum(y * np.log(1-p) + (1-y) * np.log(p))
        return ll

    def log_prior(theta):
        # å²­å›å½’å…ˆéªŒ (L2æ­£åˆ™)
        return -0.5 * np.sum(theta**2) / 2.0

    def log_prob(theta, x, y):
        lp = log_prior(theta)
        if not np.isfinite(lp): return -np.inf
        return lp + log_lik(theta, x, y)

    # åˆå§‹åŒ–
    n_walkers = max(32, 2 * n_dim)
    p0 = np.random.randn(n_walkers, n_dim) * 0.1
    
    sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_prob, args=(X, y_elim))
    sampler.run_mcmc(p0, 2000, progress=True) # æ­¥æ•°å¢åŠ ä»¥ç¡®ä¿æ”¶æ•›
    
    return sampler.get_chain(discard=1000, flat=True)

# æ‹†åˆ†è®­ç»ƒ
# æ’åæ³•èµ›å­£ï¼š1,2, 28-34
rank_seasons = [1, 2] + list(range(28, 35))
mask_rank = df['season'].isin(rank_seasons)

# 1. è®­ç»ƒæ¨¡å‹ (Target: actual_eliminate)
# æ³¨æ„ï¼šæˆ‘ä»¬è¿™é‡Œç›´æ¥ç”¨ "æ˜¯å¦æ·˜æ±°" ä½œä¸ºç¡¬æŒ‡æ ‡è®­ç»ƒï¼Œ
# ç³»æ•° (theta) å°†å‘Šè¯‰æˆ‘ä»¬ï¼šåœ¨ç»™å®šè¯„å§”åˆ†(Judge_Influence)çš„æƒ…å†µä¸‹ï¼Œ
# å¹´é¾„ã€è¡Œä¸šç­‰ç‰¹å¾å¦‚ä½•é¢å¤–å½±å“ç”Ÿå­˜ç‡(å³ç²‰ä¸ç¥¨ä»“)ã€‚
samples_rank = run_better_mcmc(X_all[mask_rank], df[mask_rank]['actual_eliminate'].values, "Rank_Era")
samples_pct = run_better_mcmc(X_all[~mask_rank], df[~mask_rank]['actual_eliminate'].values, "Percent_Era")

# ===================== 5. ä»¿çœŸä¸é¢„æµ‹ (æ··åˆæœºåˆ¶) =====================
def simulate_elimination(df, X_all, samples_rank, samples_pct, mask_rank):
    print("\nâš™ï¸ æ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦ä»¿çœŸ (ç»“åˆçœŸå®è¯„å§”åˆ† + é¢„æµ‹ç²‰ä¸åˆ†)...")
    
    # 1. è®¡ç®— "ç²‰ä¸ç”Ÿå­˜æŒ‡æ•°" (Fan Survival Score)
    # ä½¿ç”¨åéªŒå‡å€¼
    beta_rank = samples_rank.mean(axis=0)
    beta_pct = samples_pct.mean(axis=0)
    
    df['pred_fan_score'] = 0.0
    
    # åˆ†åˆ«è®¡ç®—
    df.loc[mask_rank, 'pred_fan_score'] = np.dot(X_all[mask_rank], beta_rank)
    df.loc[~mask_rank, 'pred_fan_score'] = np.dot(X_all[~mask_rank], beta_pct)
    
    # 2. ç»“åˆè¯„å§”åˆ†è®¡ç®—æ·˜æ±°æ¦‚ç‡
    # è¿™é‡Œçš„é€»è¾‘å¿…é¡»ç¬¦åˆç‰©ç†è§„å¾‹ï¼š
    # æ€»èƒ½åŠ› = (æƒé‡A * è¯„å§”åˆ†) + (æƒé‡B * ç²‰ä¸åˆ†)
    # æ¨¡å‹å…¶å®å·²ç»éšå¼å­¦ä¹ äº†æƒé‡ï¼ˆé€šè¿‡å›å½’ç³»æ•°ï¼‰
    # pred_fan_score å®é™…ä¸Šå·²ç»æ˜¯ "Log-Odds of Survival"
    
    # æˆ‘ä»¬ç›´æ¥è½¬æ¢æˆæ¦‚ç‡
    logits = df['pred_fan_score'].values
    survival_prob = 1.0 / (1.0 + np.exp(-logits))
    
    # ä¿®æ­£ï¼šæ·˜æ±°æ¦‚ç‡ = 1 - ç”Ÿå­˜æ¦‚ç‡
    df['eliminate_prob'] = 1.0 - survival_prob
    
    # 3. èµ›å­£å†…å½’ä¸€åŒ– (Softmax)
    # å› ä¸ºæ¯å‘¨å¿…å®šæ·˜æ±°ä¸€äºº(æˆ–å¤šäºº)ï¼Œæˆ‘ä»¬æœ€å¥½åœ¨æ¯å‘¨å†…éƒ¨æ¯”è¾ƒæ¦‚ç‡
    df['final_elim_prob'] = 0.0
    df['est_eliminate'] = 0  # åˆå§‹åŒ–é¢„æµ‹æ·˜æ±°åˆ—
    
    for s in df['season'].unique():
        for w in df[df['season']==s]['week'].unique():
            idx = (df['season']==s) & (df['week']==w)
            if idx.sum() == 0: continue
            
            # æ£€æŸ¥æœ¬å‘¨æ˜¯å¦æœ‰å®é™…æ·˜æ±°
            actual_elim_count = df.loc[idx, 'actual_eliminate'].sum()
            
            if actual_elim_count > 0:
                # æœ¬å‘¨æœ‰æ·˜æ±°ï¼Œæˆ‘ä»¬é¢„æµ‹è°è¢«æ·˜æ±°
                probs = df.loc[idx, 'eliminate_prob'].values
                # Softmax å½’ä¸€åŒ–ï¼Œè®©è¿™å‘¨æ€»å¾—æœ‰äººæ·˜æ±°
                # ä¸ºäº†æ‹‰å¤§å·®è·ï¼Œå¯ä»¥åŠ ä¸ª Temperature
                probs_exp = np.exp(probs * 2) 
                probs_norm = probs_exp / np.sum(probs_exp)
                
                df.loc[idx, 'final_elim_prob'] = probs_norm
                
                # æ ‡è®°é¢„æµ‹ç»“æœ (æ¦‚ç‡æœ€å¤§çš„é‚£ä¸ªäºº)
                best_guess_idx = df[idx]['final_elim_prob'].idxmax()
                df.loc[best_guess_idx, 'est_eliminate'] = 1
            else:
                # æœ¬å‘¨æ²¡æœ‰æ·˜æ±°ï¼ˆæ¯”å¦‚å†³èµ›å‘¨ï¼‰ï¼Œæ‰€æœ‰äººé¢„æµ‹ä¸ºæ™‹çº§
                df.loc[idx, 'est_eliminate'] = 0
                df.loc[idx, 'final_elim_prob'] = df.loc[idx, 'eliminate_prob'].values
            
    return df

df = simulate_elimination(df, X_all, samples_rank, samples_pct, mask_rank)

# ===================== 6. éªŒè¯ä¸å¯è§†åŒ– =====================
def check_performance(df):
    # åªçœ‹æœ‰æ·˜æ±°å‘ç”Ÿçš„å‘¨ï¼ˆè¿‡æ»¤æ‰å…¨å‘˜æ™‹çº§çš„å‘¨ï¼Œå¦‚æœæœ‰çš„è¯ï¼‰
    valid_df = df[df['actual_eliminate'].isin([0, 1])]
    
    acc = accuracy_score(valid_df['actual_eliminate'], valid_df['est_eliminate'])
    try:
        auc = roc_auc_score(valid_df['actual_eliminate'], valid_df['final_elim_prob'])
    except:
        auc = 0.5
    
    print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
    print(f"  - å‡†ç¡®ç‡ (Accuracy): {acc:.2%} (åŸºå‡†çº¿: ~12%)") 
    print(f"  - AUC Score: {auc:.4f}")
    
    # ===================== è®¡ç®—æ¯å‘¨å‡†ç¡®ç‡ =====================
    weekly_accuracies = []
    
    for s in df['season'].unique():
        season_df = df[df['season'] == s]
        weeks = sorted(season_df['week'].unique())
        
        for w in weeks:
            week_df = season_df[season_df['week'] == w]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„æ·˜æ±°æ•°æ®
            if week_df['actual_eliminate'].isin([0, 1]).any():
                # è®¡ç®—æœ¬å‘¨å‡†ç¡®ç‡
                week_acc = accuracy_score(week_df['actual_eliminate'], week_df['est_eliminate'])
                
                # ç»Ÿè®¡ä¿¡æ¯
                week_samples = len(week_df)
                week_actual_elim = week_df['actual_eliminate'].sum()
                week_pred_elim = week_df['est_eliminate'].sum()
                
                weekly_accuracies.append({
                    'season': s,
                    'week': w,
                    'accuracy': week_acc,
                    'samples': week_samples,
                    'actual_eliminations': int(week_actual_elim),
                    'predicted_eliminations': int(week_pred_elim),
                    'correct_predictions': int((week_df['actual_eliminate'] == week_df['est_eliminate']).sum()),
                    'incorrect_predictions': int((week_df['actual_eliminate'] != week_df['est_eliminate']).sum())
                })
    
    weekly_acc_df = pd.DataFrame(weekly_accuracies)
    
    # æ‰“å°æ¯å‘¨å‡†ç¡®ç‡
    if not weekly_acc_df.empty:
        print("\nğŸ“ˆ æ¯å‘¨é¢„æµ‹å‡†ç¡®ç‡:")
        print("-" * 80)
        
        # æŒ‰èµ›å­£åˆ†ç»„æ˜¾ç¤º
        for season in sorted(weekly_acc_df['season'].unique()):
            season_weeks = weekly_acc_df[weekly_acc_df['season'] == season].sort_values('week')
            print(f"\nèµ›å­£ {season}:")
            print(f"{'å‘¨æ¬¡':<6} {'å‡†ç¡®ç‡':<10} {'æ ·æœ¬æ•°':<8} {'å®é™…æ·˜æ±°':<10} {'é¢„æµ‹æ·˜æ±°':<10} {'æ­£ç¡®é¢„æµ‹':<10} {'é”™è¯¯é¢„æµ‹':<10}")
            print("-" * 80)
            
            season_accuracy_sum = 0
            week_count = 0
            
            for _, row in season_weeks.iterrows():
                print(f"{row['week']:<6} {row['accuracy']:<10.2%} {row['samples']:<8} {row['actual_eliminations']:<10} "
                      f"{row['predicted_eliminations']:<10} {row['correct_predictions']:<10} {row['incorrect_predictions']:<10}")
                
                season_accuracy_sum += row['accuracy']
                week_count += 1
            
            if week_count > 0:
                season_avg = season_accuracy_sum / week_count
                print(f"èµ›å­£ {season} å¹³å‡å‡†ç¡®ç‡: {season_avg:.2%}")
        
        # è®¡ç®—æ€»ä½“å¹³å‡æ¯å‘¨å‡†ç¡®ç‡
        avg_weekly_acc = weekly_acc_df['accuracy'].mean()
        print(f"\nğŸ“Š å¹³å‡æ¯å‘¨å‡†ç¡®ç‡: {avg_weekly_acc:.2%}")
        
        # æŒ‰å‘¨æ¬¡ç»Ÿè®¡å¹³å‡å‡†ç¡®ç‡
        print("\nğŸ“Š æŒ‰å‘¨æ¬¡ç»Ÿè®¡çš„å¹³å‡å‡†ç¡®ç‡:")
        week_avg_stats = weekly_acc_df.groupby('week')['accuracy'].agg(['mean', 'std', 'count']).reset_index()
        for _, row in week_avg_stats.iterrows():
            print(f"ç¬¬ {int(row['week']):2d} å‘¨: {row['mean']:.2%} (Â±{row['std']:.3f}, æ ·æœ¬æ•°: {int(row['count'])})")
    
    # ===================== ç»˜å›¾éƒ¨åˆ† =====================
    plt.figure(figsize=(20, 12))
    
    # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒ
    plt.subplot(2, 3, 1)
    sns.histplot(df[df['actual_eliminate']==1]['final_elim_prob'], color='red', label='Actual eliminators', kde=True, bins=20)
    sns.histplot(df[df['actual_eliminate']==0]['final_elim_prob'], color='green', label='The actual finalist', kde=True, bins=20, alpha=0.3)
    plt.title("Predicting the elimination probability distribution (higher red-green separation is better)")
    plt.legend()
    
    # å­å›¾2: å„èµ›å­£é¢„æµ‹å‡†ç¡®ç‡
    plt.subplot(2, 3, 2)
    season_acc = df.groupby('season').apply(lambda x: accuracy_score(x['actual_eliminate'], x['est_eliminate'])).reset_index()
    season_acc.columns = ['season', 'acc']
    sns.barplot(x='season', y='acc', data=season_acc, palette='viridis')
    plt.axhline(y=acc, color='r', linestyle='--', label='Overall average accuracy')
    plt.title("Prediction accuracy by season")
    plt.xticks(rotation=90, fontsize=8)
    plt.legend()
    
    # å­å›¾3: æ¯å‘¨å‡†ç¡®ç‡çƒ­åŠ›å›¾
    plt.subplot(2, 3, 3)
    if not weekly_acc_df.empty:
        # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
        heatmap_data = weekly_acc_df.pivot(index='season', columns='week', values='accuracy')
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='YlOrRd', 
                   cbar_kws={'label': 'accuracy'}, vmin=0, vmax=1)
        plt.title("Heatmap of weekly prediction accuracy")
        plt.xlabel("Time of week")
        plt.ylabel("Season")
    else:
        plt.text(0.5, 0.5, "Weekly accuracy data is not available", ha='center', va='center')
        plt.title("Heatmap of weekly prediction accuracy")
    
    # å­å›¾4: æ¯å‘¨å¹³å‡å‡†ç¡®ç‡è¶‹åŠ¿
    plt.subplot(2, 3, 4)
    if not weekly_acc_df.empty:
        week_avg_acc = weekly_acc_df.groupby('week')['accuracy'].agg(['mean', 'std']).reset_index()
        plt.errorbar(week_avg_acc['week'], week_avg_acc['mean'], 
                    yerr=week_avg_acc['std'], fmt='bo-', linewidth=2, 
                    markersize=8, capsize=5, capthick=2)
        plt.fill_between(week_avg_acc['week'], 
                        week_avg_acc['mean'] - week_avg_acc['std'],
                        week_avg_acc['mean'] + week_avg_acc['std'],
                        alpha=0.2)
        plt.axhline(y=avg_weekly_acc, color='r', linestyle='--', label=f'average: {avg_weekly_acc:.2%}')
        plt.xlabel("Time of week")
        plt.ylabel("Average precision")
        plt.title("Trend of average weekly accuracy (with error bars)")
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # å­å›¾5: æ ·æœ¬æ•°é‡åˆ†å¸ƒ
    plt.subplot(2, 3, 5)
    if not weekly_acc_df.empty:
        plt.bar(range(len(weekly_acc_df)), weekly_acc_df['samples'], alpha=0.7)
        plt.xlabel("Index of data points (sorted by season and week)")
        plt.ylabel("Number of samples")
        plt.title("Distribution of the number of samples in each week")
        plt.text(0.05, 0.95, f"Total number of samples: {len(valid_df)}", 
                transform=plt.gca().transAxes, verticalalignment='top')
    
    # å­å›¾6: å‡†ç¡®ç‡ä¸æ ·æœ¬é‡å…³ç³»
    plt.subplot(2, 3, 6)
    if not weekly_acc_df.empty and len(weekly_acc_df) > 5:
        plt.scatter(weekly_acc_df['samples'], weekly_acc_df['accuracy'], 
                   c=weekly_acc_df['week'], cmap='viridis', s=100, alpha=0.7)
        plt.xlabel("Number of samples")
        plt.ylabel("accuracy")
        plt.title("Accuracy versus sample size")
        plt.colorbar(label='Time of week')
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        z = np.polyfit(weekly_acc_df['samples'], weekly_acc_df['accuracy'], 1)
        p = np.poly1d(z)
        x_range = np.linspace(weekly_acc_df['samples'].min(), weekly_acc_df['samples'].max(), 100)
        plt.plot(x_range, p(x_range), "r--", alpha=0.5, label='Trend line')
        plt.legend()
    
    plt.tight_layout()
    plt.savefig('Task1_High_Accuracy_Report.png', dpi=300)
    print("\nâœ… å›¾è¡¨å·²ä¿å­˜: Task1_High_Accuracy_Report.png")
    
    # ä¿å­˜æ¯å‘¨å‡†ç¡®ç‡åˆ°Excel
    if not weekly_acc_df.empty:
        # æ·»åŠ æ›´å¤šç»Ÿè®¡ä¿¡æ¯
        weekly_acc_df['error_rate'] = 1 - weekly_acc_df['accuracy']
        weekly_acc_df['prediction_correctness'] = weekly_acc_df['correct_predictions'] / weekly_acc_df['samples']
        
        weekly_acc_df.to_excel("Task1_Weekly_Accuracy.xlsx", index=False)
        print("âœ… æ¯å‘¨å‡†ç¡®ç‡æ•°æ®å·²ä¿å­˜: Task1_Weekly_Accuracy.xlsx")
    
    return season_acc, weekly_acc_df

season_stats, weekly_stats = check_performance(df)

# å¯¼å‡ºé¢„æµ‹ç»“æœ
df.to_excel("Task1_Optimized_Result.xlsx", index=False)
print("âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: Task1_Optimized_Result.xlsx")

# æ‰“å°æ±‡æ€»ç»Ÿè®¡
print("\n" + "="*80)
print("ğŸ¯ é¢„æµ‹æ€§èƒ½æ±‡æ€»")
print("="*80)

if not weekly_stats.empty:
    # æŒ‰å‘¨æ¬¡ç»Ÿè®¡
    print("\næŒ‰å‘¨æ¬¡ç»Ÿè®¡:")
    week_summary = weekly_stats.groupby('week').agg({
        'accuracy': ['mean', 'std', 'min', 'max'],
        'samples': 'sum'
    }).round(4)
    print(week_summary)
    
    # æŒ‰èµ›å­£ç»Ÿè®¡
    print("\næŒ‰èµ›å­£ç»Ÿè®¡:")
    season_summary = weekly_stats.groupby('season').agg({
        'accuracy': ['mean', 'std', 'min', 'max'],
        'samples': 'sum',
        'correct_predictions': 'sum',
        'incorrect_predictions': 'sum'
    }).round(4)
    print(season_summary)