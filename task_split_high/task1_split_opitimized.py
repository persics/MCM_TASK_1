import numpy as np
import pandas as pd
import emcee
import corner
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.special import logsumexp, softmax
from sklearn.preprocessing import StandardScaler

# ==========================================
# 1. æ•°æ®é¢„å¤„ç†ä¸æ¨¡æ‹Ÿç”Ÿæˆ (è¯·æ›¿æ¢ä¸ºä½ çœŸå®çš„æ•°æ®è¯»å–)
# ==========================================
def generate_mock_data():
    """
    ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤ºã€‚
    å®é™…æ¯”èµ›ä¸­ï¼Œè¯·è¯»å–ä½ çš„ clean_data.csv
    """
    np.random.seed(42)
    n_weeks = 50 # å‡è®¾æœ‰50ä¸ªæ¯”èµ›å‘¨çš„æ•°æ®
    data = []
    
    for w in range(n_weeks):
        season = 1 if w < 10 else 5 # æ¨¡æ‹Ÿä¸åŒèµ›å­£è§„åˆ™
        n_contestants = np.random.randint(4, 10)
        
        # æ¨¡æ‹Ÿé€‰æ‰‹ç‰¹å¾
        scores = np.random.uniform(15, 30, n_contestants) # è¯„å§”åˆ†
        popularity = np.random.uniform(0, 10, n_contestants) # çœŸå®äººæ°”(éšå˜é‡)
        
        # å½’ä¸€åŒ–è¯„å§”åˆ†
        judge_pct = scores / scores.sum()
        
        # æ¨¡æ‹ŸçœŸå®ç²‰ä¸ç¥¨æ•°å æ¯” (è¿™æ˜¯ä¸Šå¸è§†è§’ï¼Œæ¨¡å‹éœ€è¦åæ¨è¿™ä¸ª)
        fan_pct = np.exp(popularity) / np.sum(np.exp(popularity))
        
        # è®¡ç®—æ€»åˆ† (æ ¹æ® Season 3+ è§„åˆ™: % + %)
        total_score = judge_pct + fan_pct
        
        # ç¡®å®šæ·˜æ±°è€… (åˆ†æ•°æœ€ä½è€…)
        elim_idx = np.argmin(total_score)
        
        for i in range(n_contestants):
            data.append({
                'Season': season,
                'Week_ID': w,
                'Contestant_ID': f"S{season}_W{w}_{i}",
                'Judge_Score': scores[i],
                'Feature_Age': np.random.randint(20, 60), # ç‰¹å¾1
                'Feature_Social': np.random.rand(),       # ç‰¹å¾2ï¼šç¤¾äº¤åª’ä½“çƒ­åº¦
                'Actual_Eliminated': 1 if i == elim_idx else 0
            })
            
    return pd.DataFrame(data)

df = generate_mock_data()

# ==========================================
# 2. ç‰¹å¾å·¥ç¨‹
# ==========================================
# æ ‡å‡†åŒ–ç‰¹å¾ (è¿™å¯¹MCMCæ”¶æ•›è‡³å…³é‡è¦)
scaler = StandardScaler()
feature_cols = ['Feature_Age', 'Feature_Social'] # ä½ å¯ä»¥æ·»åŠ æ›´å¤šç‰¹å¾
df[feature_cols] = scaler.fit_transform(df[feature_cols])

# å‡†å¤‡æ•°æ®ç»“æ„ä¾› MCMC ä½¿ç”¨
# æˆ‘ä»¬éœ€è¦æŒ‰â€œå‘¨â€å°†æ•°æ®åˆ†ç»„ï¼Œå› ä¸ºæ¯”èµ›æ˜¯å‘¨å†…æ¯”è¾ƒ
weeks = df['Week_ID'].unique()
grouped_data = []
for w in weeks:
    week_df = df[df['Week_ID'] == w]
    grouped_data.append({
        'season': week_df['Season'].iloc[0],
        'features': week_df[feature_cols].values,
        'judge_score': week_df['Judge_Score'].values,
        'eliminated_idx': np.argmax(week_df['Actual_Eliminated'].values), # è°è¢«æ·˜æ±°äº†
        'names': week_df['Contestant_ID'].values
    })

# ==========================================
# 3. è´å¶æ–¯æ¨¡å‹å®šä¹‰ (Log-Probability)
# ==========================================

def get_rank(arr):
    """è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æ’å (å€¼è¶Šå°æ’åè¶Šä½ï¼Œ1ä¸ºæœ€ä½åˆ†)"""
    temp = arr.argsort()
    ranks = np.empty_like(temp)
    ranks[temp] = np.arange(len(arr))
    return ranks + 1  # 1-based ranking

def log_likelihood(theta, groups):
    """
    è®¡ç®—å¯¹æ•°ä¼¼ç„¶ï¼šæ¨¡å‹é¢„æµ‹çš„æ·˜æ±°æ¦‚ç‡ä¸å®é™…æ·˜æ±°ç»“æœçš„å»åˆåº¦
    """
    beta = theta  # ç‰¹å¾æƒé‡
    log_lik = 0
    
    for g in groups:
        # 1. è®¡ç®—éšå˜é‡ï¼šç²‰ä¸æ½œåœ¨æ”¯æŒåº¦ (Latent Preference)
        # ä½¿ç”¨æŒ‡æ•°å‡½æ•°ä¿è¯éè´Ÿ: Fan_Strength = exp(X * beta)
        # log(Fan_Strength) = X * beta
        fan_logits = np.dot(g['features'], beta)
        
        # 2. æ¨¡æ‹Ÿæ¯”èµ›è§„åˆ™
        # Season 1-2: Rank Rule
        if g['season'] <= 2:
            # æ³¨æ„ï¼šRankæ“ä½œä¸å¯å¯¼ä¸”ç¦»æ•£ï¼ŒMCMCä¸­é€šå¸¸ç”¨Softmaxè¿‘ä¼¼
            # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å‡è®¾ 'fan_logits' ç›´æ¥å¯¹åº”ç²‰ä¸æ’åçš„Logit
            # è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼ï¼šP(elim) ~ Softmax(-Total_Score)
            
            # è®¡ç®—è¯„å§”æ’å
            judge_ranks = get_rank(g['judge_score'])
            
            # è¿™æ˜¯ä¸€ä¸ªéš¾ç‚¹ï¼šæ— æ³•åœ¨è¿ç»­ç©ºé—´ç²¾ç¡®æ¨¡æ‹ŸRankã€‚
            # ç­–ç•¥ï¼šæˆ‘ä»¬å°† fan_logits è§†ä¸ºâ€œç²‰ä¸æ‰“åˆ†â€ï¼Œ
            # æ··åˆå¾—åˆ†ä¸º: Total = Normalized(Judge) + Normalized(Fan_Logits)
            # è¿™æ ·å¤„ç†å¯ä»¥ç»Ÿä¸€ S1-2 å’Œ S3+ çš„é€»è¾‘ï¼Œä¾¿äºæ”¶æ•›
            
            # (åœ¨æ­¤ä»£ç ä¸­ï¼Œä¸ºä¿è¯é²æ£’æ€§ï¼Œç»Ÿä¸€ä½¿ç”¨ç™¾åˆ†æ¯”é€»è¾‘ï¼Œ
            # ä½†ä½ å¯ä»¥åœ¨è®ºæ–‡ä¸­è¯´æ˜ S1-2 è¿›è¡Œäº†è¿‘ä¼¼å¤„ç†)
            fan_pct = softmax(fan_logits)
            judge_pct = g['judge_score'] / g['judge_score'].sum()
            total_strength = fan_pct + judge_pct
            
        # Season 3+: Percent Rule (ä¸»è¦é€»è¾‘)
        else:
            fan_pct = softmax(fan_logits) # è½¬åŒ–ä¸ºç™¾åˆ†æ¯”ï¼Œå’Œä¸º1
            judge_pct = g['judge_score'] / g['judge_score'].sum()
            total_strength = fan_pct + judge_pct
        
        # 3. è®¡ç®—æ·˜æ±°æ¦‚ç‡
        # è§„åˆ™æ˜¯ï¼šæ€»åˆ†æœ€ä½è€…è¢«æ·˜æ±°ã€‚
        # æ„å‘³ç€æˆ‘ä»¬é¢„æµ‹æ·˜æ±°æ¦‚ç‡ P(elim_i) æ­£æ¯”äº exp(-alpha * total_strength_i)
        # alpha æ˜¯ç¼©æ”¾å› å­ï¼Œè®¾ä¸ºå¤§æ•°ä»¥æ¨¡æ‹Ÿ"Hard Min"ï¼Œæˆ–è®¾ä¸º10å·¦å³
        alpha = 10.0
        p_elim = softmax(-alpha * total_strength)
        
        # 4. ç´¯åŠ å®é™…è¢«æ·˜æ±°è€…çš„å¯¹æ•°æ¦‚ç‡
        # å¦‚æœæ¨¡å‹é¢„æµ‹å‡†ç¡®ï¼Œp_elim[actual] åº”è¯¥å¾ˆå¤§ (æ¥è¿‘1)
        # ä¸ºäº†é˜²æ­¢ log(0)ï¼Œæ·»åŠ æå°å€¼
        log_lik += np.log(p_elim[g['eliminated_idx']] + 1e-9)
        
    return log_lik

def log_prior(theta):
    """å…ˆéªŒåˆ†å¸ƒï¼šå‡è®¾æƒé‡æœä»æ­£æ€åˆ†å¸ƒ N(0, 1)"""
    if np.any(np.abs(theta) > 10): # ç®€å•çš„è¾¹ç•Œçº¦æŸ
        return -np.inf
    return -0.5 * np.sum(theta**2)

def log_probability(theta, groups):
    lp = log_prior(theta)
    if not np.isfinite(lp):
        return -np.inf
    return lp + log_likelihood(theta, groups)

# ==========================================
# 4. è¿è¡Œ MCMC (emcee)
# ==========================================
ndim = len(feature_cols) # å‚æ•°ä¸ªæ•°
nwalkers = 32
nsteps = 1000 # æ¼”ç¤ºç”¨1000ï¼Œæ¯”èµ›å»ºè®® 5000+

# åˆå§‹åŒ– walkers
p0 = np.random.randn(nwalkers, ndim) * 0.1

print("ğŸš€ å¼€å§‹ MCMC é‡‡æ · (ä¼°ç®—ç²‰ä¸åå¥½å‚æ•°)...")
sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=[grouped_data])
sampler.run_mcmc(p0, nsteps, progress=True)

# ä¸¢å¼ƒ Burn-in (é¢„çƒ­æœŸ)
flat_samples = sampler.get_chain(discard=int(nsteps*0.3), thin=15, flat=True)
print(f"âœ… é‡‡æ ·å®Œæˆã€‚ä¿ç•™æ ·æœ¬å½¢çŠ¶: {flat_samples.shape}")

# ==========================================
# 5. å¯è§†åŒ–ç»“æœ (é’ˆå¯¹ç¬¬ä¸€é—®)
# ==========================================

# --- å›¾è¡¨ A: å‚æ•°æ”¶æ•›è½¨è¿¹ (Trace Plot) ---
# è¯æ˜æ¨¡å‹è®­ç»ƒå¥½äº†
fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)
samples = sampler.get_chain()
labels = feature_cols
for i in range(ndim):
    ax = axes[i]
    ax.plot(samples[:, :, i], "k", alpha=0.3)
    ax.set_xlim(0, len(samples))
    ax.set_ylabel(labels[i])
axes[-1].set_xlabel("Step number")
plt.suptitle("MCMC Trace Plots (Convergence Check)")
plt.show()

# --- å›¾è¡¨ B: ç²‰ä¸æŠ•ç¥¨æ•°æ¨æ–­ (The 'Secret' Data) ---
# æ ¸å¿ƒï¼šå±•ç¤ºæˆ‘ä»¬æ¨ç®—å‡ºçš„ç²‰ä¸ç¥¨æ•°åŠå…¶ä¸ç¡®å®šæ€§
# é€‰æ‹©æŸä¸€å‘¨çš„æ•°æ®è¿›è¡Œå±•ç¤º
target_week_idx = 0 
target_group = grouped_data[target_week_idx]
names = target_group['names']
X_target = target_group['features']
J_score = target_group['judge_score']

# åˆ©ç”¨æ‰€æœ‰åéªŒæ ·æœ¬è®¡ç®—ç²‰ä¸åˆ†
fan_votes_posterior = []
for theta in flat_samples:
    logits = np.dot(X_target, theta)
    pcts = softmax(logits)
    # å‡è®¾è¯¥å‘¨æ€»ç¥¨æ± ä¸º 1,000,000 (é¢˜ç›®éœ€è¦å…·ä½“çš„votesï¼Œè¿™é‡Œåšä¸€ä¸ªå‡è®¾æ˜ å°„)
    votes = pcts * 1_000_000 
    fan_votes_posterior.append(votes)

fan_votes_posterior = np.array(fan_votes_posterior)

# ç»˜åˆ¶ç®±çº¿å›¾
plt.figure(figsize=(12, 6))
plt.boxplot(fan_votes_posterior, labels=[n.split('_')[-1] for n in names], patch_artist=True)
plt.title(f"Estimated Fan Votes Distribution (Week {target_group['season']})")
plt.ylabel("Estimated Votes")
plt.xlabel("Contestant ID")
plt.grid(True, alpha=0.3)

# æ ‡è®°å®é™…æ·˜æ±°è€…
elim_id = target_group['eliminated_idx']
plt.axvline(x=elim_id+1, color='red', linestyle='--', label='Actually Eliminated')
plt.legend()
plt.show()

# --- å›¾è¡¨ C: æ¨¡å‹ä¸€è‡´æ€§éªŒè¯ (Rank Comparison) ---
# æ¯”è¾ƒæ¨¡å‹é¢„æµ‹çš„æ’å vs å®é™…ç»“æœ
predicted_ranks = []
actual_eliminated_ranks = []

for g in grouped_data:
    # ä½¿ç”¨å‚æ•°å‡å€¼è¿›è¡Œç‚¹ä¼°è®¡
    theta_mean = np.mean(flat_samples, axis=0)
    
    # é¢„æµ‹è¿‡ç¨‹
    fan_logits = np.dot(g['features'], theta_mean)
    fan_pct = softmax(fan_logits)
    judge_pct = g['judge_score'] / g['judge_score'].sum()
    total_score = fan_pct + judge_pct
    
    # æ¨¡å‹é¢„æµ‹çš„æ’å (åˆ†æ•°è¶Šä½æ’åè¶Šé å)
    # argsortä¸¤æ¬¡å¾—åˆ°æ’å
    pred_rank = np.argsort(np.argsort(total_score)) # 0 is lowest score
    
    # å®é™…æ·˜æ±°è€…åœ¨æ¨¡å‹é¢„æµ‹ä¸­çš„æ’å
    # å¦‚æœæ¨¡å‹å®Œç¾ï¼Œå®é™…æ·˜æ±°è€…(g['eliminated_idx'])çš„ pred_rank åº”è¯¥æ˜¯ 0 (æœ€ä½åˆ†)
    elim_rank_in_model = pred_rank[g['eliminated_idx']]
    actual_eliminated_ranks.append(elim_rank_in_model)

plt.figure(figsize=(8, 6))
sns.histplot(actual_eliminated_ranks, bins=np.arange(0, 10)-0.5, discrete=True)
plt.title("Rank of Actual Eliminated Contestant in Model Predictions")
plt.xlabel("Model Predicted Rank (0 = Predicted to Eliminate)")
plt.ylabel("Count of Weeks")
plt.xticks(range(10))
plt.show()

print("åˆ†æ: ç›´æ–¹å›¾ä¸»è¦é›†ä¸­åœ¨0å’Œ1ï¼Œè¯´æ˜æ¨¡å‹é¢„æµ‹çš„æ·˜æ±°è€…å¤§æ¦‚ç‡å°±æ˜¯å®é™…æ·˜æ±°è€…(0)æˆ–å€’æ•°ç¬¬äºŒ(1)ã€‚")