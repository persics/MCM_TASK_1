# ===================== 1. åŸºç¡€è®¾ç½®ä¸å¯¼å…¥ =====================
import numpy as np
if not hasattr(np, 'bool'):
    np.bool = np.bool_
    np.int = np.int_

import emcee
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from warnings import filterwarnings

filterwarnings('ignore')

# ç»˜å›¾é…ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.facecolor'] = 'white'
np.random.seed(42)

# ===================== 2. è¯»å–æ•°æ® =====================
def read_your_data():
    file_path = "2026_MCM_Problem_C_Data.csv"
    df = pd.read_csv(file_path, encoding='utf-8-sig')
    total_samples = len(df)
    total_seasons = 34

    # è‡ªåŠ¨ç”Ÿæˆseasonå­—æ®µ
    season_sample_counts = [12]*21 + [13]*13
    df['season'] = np.repeat(range(1, total_seasons+1), season_sample_counts)[:total_samples]

    # ç”Ÿæˆå»ºæ¨¡æ ‡ç­¾
    df['actual_eliminate'] = df['results'].apply(lambda x: 0 if 'Place' in str(x) else 1)
    df['final_rank'] = df['placement'].astype(int)

    # ç”Ÿæˆweekå­—æ®µ
    if 'week' not in df.columns:
        df['week'] = df.groupby('season').cumcount() + 1
        df['week'] = df['week'].apply(lambda x: min(x, 5))

    # ç”Ÿæˆplayer_id
    if 'player_id' not in df.columns:
        df['player_id'] = [f'C{i+1:03d}' for i in range(total_samples)]

    return df

df = read_your_data()

# ===================== 3. æ•°æ®é¢„å¤„ç†ï¼ˆå…¨å±€ç¼–ç ï¼Œå±€éƒ¨æ‹†åˆ†ï¼‰ =====================
def preprocess_data_split(df):
    # å®šä¹‰ç‰¹å¾
    cat_feats = ['celebrity_homecountry/region', 'celebrity_homestate', 'celebrity_industry']
    cont_feats = ['celebrity_age_during_season'] # æ³¨æ„ï¼šfinal_rankæ˜¯Yï¼Œä¸æ”¾å…¥X

    # 1. å…¨å±€æ‹ŸåˆEncoderå’ŒScalerï¼ˆä¿è¯ä¸¤ç»„æ¨¡å‹çš„ç‰¹å¾ç»´åº¦ä¸€è‡´ï¼Œä¾¿äºå¯¹æ¯”ï¼‰
    encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
    scaler = StandardScaler()

    # å¡«å……ç¼ºå¤±å€¼
    df['celebrity_age_during_season'] = df['celebrity_age_during_season'].fillna(
        df['celebrity_age_during_season'].mean()
    ).astype(int)
    for col in cat_feats:
        df[col] = df[col].fillna('Unknown').astype(str)

    # æ‹Ÿåˆè½¬æ¢
    X_cat = encoder.fit_transform(df[cat_feats])
    X_cont = scaler.fit_transform(df[cont_feats])
    
    # ç”Ÿæˆåˆ—å
    cat_cols = []
    for i, feat in enumerate(cat_feats):
        unique_vals = encoder.categories_[i][1:]
        cat_cols.extend([f'{feat}_{str(val).replace("/", "-").replace(" ", "_")}' for val in unique_vals])
    
    feature_names = ['intercept'] + cat_cols + cont_feats
    
    # æ„å»ºå…¨å±€XçŸ©é˜µ
    X_all = np.hstack([np.ones((len(df), 1)), X_cat, X_cont])
    y_all = df['final_rank'].values

    # 2. æ‹†åˆ†æ•°æ®é›†ï¼šæ’åæ³•èµ›å­£ vs ç™¾åˆ†æ¯”æ³•èµ›å­£
    # æ’åæ³•èµ›å­£ï¼š1, 2, 28-34
    rank_seasons = [1, 2] + list(range(28, 35))
    
    mask_rank = df['season'].isin(rank_seasons)
    mask_percent = ~df['season'].isin(rank_seasons)

    data_split = {
        'rank': {
            'X': X_all[mask_rank],
            'y': y_all[mask_rank],
            'indices': df[mask_rank].index
        },
        'percent': {
            'X': X_all[mask_percent],
            'y': y_all[mask_percent],
            'indices': df[mask_percent].index
        }
    }
    
    print(f"\nğŸ“Š æ•°æ®æ‹†åˆ†å®Œæˆï¼š")
    print(f"  - æ’åæ³•æ•°æ®ï¼ˆRank Modelï¼‰ï¼š{mask_rank.sum()} æ ·æœ¬ (Seasons: 1-2, 28-34)")
    print(f"  - ç™¾åˆ†æ¯”æ³•æ•°æ®ï¼ˆPercent Modelï¼‰ï¼š{mask_percent.sum()} æ ·æœ¬ (Seasons: 3-27)")
    print(f"  - ç‰¹å¾ç»´åº¦ï¼š{X_all.shape[1]}")

    return df, data_split, feature_names

df, data_split, feature_names = preprocess_data_split(df)

# ===================== 4. é€šç”¨è´å¶æ–¯MCMCè®­ç»ƒå‡½æ•° =====================
def run_mcmc_model(X, y, model_name="Model"):
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {model_name} ...")
    
    # å…ˆéªŒ
    def log_prior(theta):
        # å¼±ä¿¡æ¯å…ˆéªŒ
        if np.abs(theta[0]) > 100: return -np.inf # æˆªè·çº¦æŸ
        return -0.5 * np.sum(theta**2 / 25) # N(0, 5)

    # ä¼¼ç„¶ (å›å½’æ¨¡å‹ï¼šlatent_score ~ Normal)
    def log_likelihood(theta, X, y):
        mu = np.dot(X, theta)
        sigma = 1.2 # å›ºå®šå™ªå£°ï¼Œä¹Ÿå¯è®¾ä¸ºå‚æ•°
        return np.sum(stats.norm.logpdf(y, mu, sigma))

    # åéªŒ
    def log_probability(theta, X, y):
        lp = log_prior(theta)
        if not np.isfinite(lp): return -np.inf
        return lp + log_likelihood(theta, X, y)

    # MCMC è®¾ç½®
    n_params = X.shape[1]
    n_walkers = max(32, 2 * n_params)
    initial = np.random.normal(0, 0.1, (n_walkers, n_params))
    
    sampler = emcee.EnsembleSampler(n_walkers, n_params, log_probability, args=(X, y))
    sampler.run_mcmc(initial, 4000, progress=True)
    
    samples = sampler.get_chain(discard=1500, flat=True)
    return samples

# ===================== 5. åˆ†åˆ«è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ =====================

# 1. è®­ç»ƒæ’åæ³•æ¨¡å‹ (Rank Seasons)
print("--- æ­£åœ¨æ‹Ÿåˆæ’åæ³•æ¨¡å‹ (Rank Model) ---")
samples_rank = run_mcmc_model(data_split['rank']['X'], data_split['rank']['y'], "Rank_Model")

# 2. è®­ç»ƒç™¾åˆ†æ¯”æ³•æ¨¡å‹ (Percent Seasons)
print("--- æ­£åœ¨æ‹Ÿåˆç™¾åˆ†æ¯”æ³•æ¨¡å‹ (Percent Model) ---")
samples_percent = run_mcmc_model(data_split['percent']['X'], data_split['percent']['y'], "Percent_Model")

# ===================== 6. åéªŒæ¨æ–­ä¸ç»“æœåˆå¹¶ =====================
def infer_and_merge(df, data_split, samples_rank, samples_percent):
    # åˆå§‹åŒ–åˆ—
    df['est_rank'] = 0
    df['vote_posterior'] = None
    df['vote_posterior'] = df['vote_posterior'].astype(object) # å…è®¸å­˜åˆ—è¡¨

    # è¾…åŠ©æ¨æ–­å‡½æ•°
    def infer_subset(X, samples, indices):
        rank_posterior_list = []
        # æŠ½æ · 1000 æ¬¡
        subset_samples = samples[np.random.choice(len(samples), 1000, replace=False)]
        
        # æ‰¹é‡è®¡ç®—
        # X: (N_subset, n_feat), Theta: (1000, n_feat) -> Mu: (N_subset, 1000)
        mu_mat = np.dot(X, subset_samples.T)
        
        # æ·»åŠ å™ªå£°å¹¶å–æ•´
        pred_mat = np.round(mu_mat + np.random.normal(0, 1.2, mu_mat.shape))
        pred_mat[pred_mat < 1] = 1 # æˆªæ–­
        
        # å­˜å› DataFrame
        est_ranks = np.mean(pred_mat, axis=1).astype(int)
        
        # æ›´æ–°df
        df.loc[indices, 'est_rank'] = est_ranks
        
        # è¿™ç§æ–¹å¼ç¨æ…¢ä½†å®‰å…¨ï¼šé€è¡Œèµ‹å€¼posterior
        # æ„é€ ä¸€ä¸ªä¹Ÿå°±æ˜¯ (N_subset,) çš„ object æ•°ç»„
        post_objs = [row for row in pred_mat]
        df.loc[indices, 'vote_posterior'] = pd.Series(post_objs, index=indices)

    # æ¨æ–­ Rank éƒ¨åˆ†
    infer_subset(data_split['rank']['X'], samples_rank, data_split['rank']['indices'])
    
    # æ¨æ–­ Percent éƒ¨åˆ†
    infer_subset(data_split['percent']['X'], samples_percent, data_split['percent']['indices'])
    
    print("\nâœ… åŒæ¨¡å‹æ¨æ–­å®Œæˆï¼Œç»“æœå·²åˆå¹¶è‡³ä¸»DataFrame")
    return df

df = infer_and_merge(df, data_split, samples_rank, samples_percent)

# ===================== 7. æŒ‰æœºåˆ¶è®¡ç®—æ·˜æ±°æ¦‚ç‡ (å¤ç”¨é€»è¾‘) =====================
# æ³¨æ„ï¼šè¿™é‡Œé€»è¾‘ä¸ä¹‹å‰ç›¸åŒï¼Œä½†è¾“å…¥æ•°æ®æºè‡ªä¸¤ä¸ªä¸åŒè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹
def calculate_eliminate_mixed(df):
    df['est_eliminate'] = 0
    df['eliminate_prob'] = 0.0
    n_sim = 1000

    rank_seasons = [1, 2] + list(range(28, 35))
    
    for season in sorted(df['season'].unique()):
        # åˆ¤å®šè§„åˆ™
        rule = 'rank' if season in rank_seasons else 'percent'
        
        df_season = df[df['season'] == season]
        for week in df_season['week'].unique():
            idx_week = (df['season'] == season) & (df['week'] == week)
            df_week = df[idx_week]
            n_player = len(df_week)
            if n_player <= 1: continue

            # è·å–åéªŒæ ·æœ¬ (N_player, 1000)
            # æ³¨æ„ï¼švote_posterior å·²ç»æ˜¯é€šè¿‡å„è‡ªæ¨¡å‹ç”Ÿæˆçš„äº†
            vote_posterior_week = np.vstack(df_week['vote_posterior'].values)
            
            score = df_week['final_rank'].values # è¯„å§”åæ¬¡(ä»£ç†)
            
            # æ¨¡æ‹Ÿå¾ªç¯
            elim_count = np.zeros(n_player)
            
            if rule == 'rank':
                # æ’åæ³•ï¼š(è¯„å§”æ’å + ç²‰ä¸æ’å) æœ€å¤§è€…æ·˜æ±°
                rank_score = stats.rankdata(score, method='min')
                for s in range(n_sim):
                    vote_s = vote_posterior_week[:, s]
                    rank_vote_s = stats.rankdata(vote_s, method='min')
                    total = rank_score + rank_vote_s
                    # æ ‡è®°æœ€å¤§å€¼ï¼ˆå¯èƒ½æœ‰å¹¶åˆ—ï¼‰
                    elim_count[total == total.max()] += 1
                    
            elif rule == 'percent':
                # ç™¾åˆ†æ¯”æ³•ï¼š(è¯„å§”å æ¯” + ç²‰ä¸å æ¯”) æœ€å°è€…æ·˜æ±°
                # è½¬æ¢ï¼šåæ¬¡ -> åˆ†æ•° (ç®€å•åè½¬)
                raw_score = df_week['final_rank'].max() - score + 1
                p_score = raw_score / raw_score.sum()
                
                for s in range(n_sim):
                    vote_s = vote_posterior_week[:, s]
                    # è½¬æ¢ï¼šåéªŒåæ¬¡ -> è™šæ‹Ÿç¥¨æ•°
                    raw_vote = df_week['est_rank'].max() - vote_s + 1
                    raw_vote = np.maximum(raw_vote, 0.1) # é¿å…é™¤0
                    p_vote = raw_vote / raw_vote.sum()
                    
                    total_p = p_score + p_vote
                    elim_count[total_p == total_p.min()] += 1

            df.loc[idx_week, 'eliminate_prob'] = elim_count / n_sim
            
            # ç¡¬åˆ†ç±»ï¼ˆæ¦‚ç‡>0.5æˆ–æœ€å¤§è€…ï¼‰
            best_guess_idx = df_week.index[np.argmax(elim_count)]
            df.loc[idx_week, 'est_eliminate'] = 0
            df.loc[best_guess_idx, 'est_eliminate'] = 1

    return df

print("\nâš™ï¸ æ­£åœ¨åº”ç”¨å„è‡ªçš„æ·˜æ±°è§„åˆ™è®¡ç®—æ¦‚ç‡...")
df = calculate_eliminate_mixed(df)

# ===================== 8. éªŒè¯ä¸å¯¼å‡º =====================
def validate_and_export(df):
    # éªŒè¯
    acc = (df['actual_eliminate'] == df['est_eliminate']).mean()
    try:
        auc = roc_auc_score(df['actual_eliminate'], df['eliminate_prob'])
    except:
        auc = 0.5
        
    print(f"\nğŸ“Š ç»¼åˆæ¨¡å‹æ€§èƒ½ï¼š")
    print(f"  - å‡†ç¡®ç‡ (Accuracy): {acc:.2%}")
    print(f"  - AUC: {auc:.4f}")

    # å¯¹æ¯”ä¸åŒæ¨¡å‹ä¸‹çš„ç³»æ•°ï¼ˆå¯é€‰ï¼‰
    print("\nğŸ” ä¸¤ä¸ªæ¨¡å‹å¯¹'å¹´é¾„'ç‰¹å¾çš„å½±å“å¯¹æ¯” (Standardized Beta):")
    # æ‰¾åˆ°å¹´é¾„å¯¹åº”çš„ç´¢å¼•
    age_idx = feature_names.index('celebrity_age_during_season')
    beta_rank = np.mean(samples_rank[:, age_idx])
    beta_pct = np.mean(samples_percent[:, age_idx])
    print(f"  - æ’åæ³•æ—¶ä»£ (Rank Era) å¹´é¾„ç³»æ•°: {beta_rank:.4f}")
    print(f"  - ç™¾åˆ†æ¯”æ—¶ä»£ (Percent Era) å¹´é¾„ç³»æ•°: {beta_pct:.4f}")
    if abs(beta_rank - beta_pct) > 0.1:
        print("    -> å‘ç°æ˜¾è‘—å·®å¼‚ï¼šå¹´é¾„åœ¨ä¸åŒæ—¶æœŸçš„å½±å“æƒé‡ä¸åŒã€‚")

    # å¯¼å‡º
    df.to_excel("34å­£_åŒæ¨¡å‹åˆ†å±‚å»ºæ¨¡ç»“æœ.xlsx", index=False)
    print("\nğŸ“ ç»“æœå·²å¯¼å‡ºï¼š34å­£_åŒæ¨¡å‹åˆ†å±‚å»ºæ¨¡ç»“æœ.xlsx")

validate_and_export(df)