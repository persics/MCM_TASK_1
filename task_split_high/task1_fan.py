# ===================== 1. åŸºç¡€è®¾ç½® =====================
import numpy as np
if not hasattr(np, 'bool'):
    np.bool = np.bool_
    np.int = np.int_

import emcee
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.special import softmax
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import re
from warnings import filterwarnings

filterwarnings('ignore')

# ç»˜å›¾é…ç½®
import platform
font_list = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['font.sans-serif'] = font_list
plt.rcParams['axes.unicode_minus'] = False
np.random.seed(2026)

# ===================== 2. å¢å¼ºç‰ˆæ•°æ®è¯»å– =====================
def read_and_process_data():
    file_path = "2026_MCM_Problem_C_Data.csv"
    try:
        raw_df = pd.read_csv(file_path, encoding='utf-8-sig')
    except:
        raw_df = pd.read_csv(file_path, encoding='latin1')
    
    raw_df.columns = [c.lower().strip() for c in raw_df.columns]
    
    # åŸºç¡€åˆ—è¯†åˆ«
    week_cols = [c for c in raw_df.columns if 'week' in c and 'judge' in c]
    max_week = 10
    if week_cols:
        weeks = [int(re.findall(r'week\s*(\d+)', c)[0]) for c in week_cols if re.findall(r'week\s*(\d+)', c)]
        if weeks: max_week = max(weeks)

    long_data = []
    
    for idx, row in raw_df.iterrows():
        season = row.get('season', 1)
        final_rank = row.get('placement', np.nan)
        if pd.isna(final_rank) or str(final_rank) == 'nan': continue
        
        try:
            final_rank = int(str(final_rank).replace('Place', '').strip())
        except:
            final_rank = 15
            
        age = row.get('celebrity_age_during_season', 30)
        country = row.get('celebrity_homecountry/region', 'USA')
        industry = row.get('celebrity_industry', 'Actor')
        
        for w in range(1, max_week + 1):
            # æå–å½“å‘¨è¯„å§”åˆ†
            w_cols = [c for c in raw_df.columns if str(w) in c and ('judge' in c or 'score' in c)]
            current_week_scores = []
            for c in w_cols:
                val = row[c]
                try:
                    val = float(val)
                    if not pd.isna(val) and val > 0:
                        current_week_scores.append(val)
                except:
                    pass
            
            if len(current_week_scores) > 0:
                judge_total = np.sum(current_week_scores)
            else:
                judge_total = 0 
            
            if w > 1 and judge_total == 0: continue
            
            long_data.append({
                'player_id': f"S{int(season):02d}-P{idx:03d}",
                'season': int(season),
                'week': w,
                'final_rank': final_rank,
                'judge_score': judge_total,
                'age': age,
                'country': country,
                'industry': industry
            })
            
    df = pd.DataFrame(long_data)
    df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(35)
    
    # ç”Ÿæˆ "Actual Eliminate" æ ‡ç­¾
    df['actual_eliminate'] = 0
    for s in df['season'].unique():
        for w in df[df['season']==s]['week'].unique():
            mask = (df['season']==s) & (df['week']==w)
            sub = df[mask]
            if len(sub) > 1:
                max_rank = sub['final_rank'].max()
                target_ids = sub[sub['final_rank'] == max_rank]['player_id'].values
                next_week_mask = (df['season']==s) & (df['week']==w+1) & (df['player_id'].isin(target_ids))
                if not df[next_week_mask].shape[0] > 0:
                    df.loc[mask & (df['final_rank'] == max_rank), 'actual_eliminate'] = 1

    return df

print("æ­£åœ¨è§£æå¹¶é‡æ„æ•°æ®...")
df = read_and_process_data()
df = df[df['judge_score'] > 0]
print(f"æ•°æ®é‡æ„å®Œæˆï¼Œæ ·æœ¬æ•°: {len(df)}")

# ===================== 3. ç‰¹å¾å·¥ç¨‹ =====================
def prepare_features(df):
    # è¯„å§”åˆ†æ ‡å‡†åŒ–
    df['judge_score_std'] = df.groupby(['season', 'week'])['judge_score'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-5)
    )
    
    encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
    cat_features = ['industry'] 
    X_cat = encoder.fit_transform(df[cat_features])
    
    scaler = StandardScaler()
    X_num = scaler.fit_transform(df[['age']])
    
    # XçŸ©é˜µï¼šæˆªè· + è¡Œä¸š + å¹´é¾„ + è¯„å§”å½±å“åŠ›
    X_final = np.hstack([np.ones((len(df), 1)), X_cat, X_num, df[['judge_score_std']].values])
    
    feature_names = ['Intercept'] + list(encoder.get_feature_names_out()) + ['Age', 'Judge_Influence']
    
    return df, X_final, feature_names

df, X_all, feat_names = prepare_features(df)

# ===================== 4. è´å¶æ–¯ MCMC æ¨¡å‹ =====================
def run_better_mcmc(X, y_elim, model_label):
    print(f"ğŸš€ æ­£åœ¨è®­ç»ƒ {model_label} (N={len(y_elim)})...")
    n_dim = X.shape[1]
    
    def log_prob(theta, x, y):
        # å…ˆéªŒ
        lp = -0.5 * np.sum(theta**2) / 2.0
        if not np.isfinite(lp): return -np.inf
        
        # ä¼¼ç„¶: Logit
        # theta ä»£è¡¨ "ç”Ÿå­˜èƒ½åŠ›"ã€‚èƒ½åŠ›è¶Šé«˜ï¼Œy=1(æ·˜æ±°)çš„æ¦‚ç‡è¶Šä½ã€‚
        # Logits = Ability
        # P(Elim) = 1 - Sigmoid(Ability) = Sigmoid(-Ability)
        logits = np.dot(x, theta)
        
        # ä¸ºäº†æ•°å€¼ç¨³å®šï¼Œè®¡ç®— log likelihood
        # y=1 (Elim) -> want low ability -> maximize log(1-p) where p=sigmoid(logits)
        # y=0 (Safe) -> want high ability -> maximize log(p)
        
        # p = sigmoid(logits)
        # log(p) = -log(1 + exp(-logits))
        # log(1-p) = -logits - log(1 + exp(-logits))
        
        # ç®€åŒ–ç‰ˆ: ç›´æ¥ç”¨ scipy çš„ log_expit æˆ–è€…æ‰‹åŠ¨å†™ç¨³å¥å…¬å¼
        # è¿™é‡Œç”¨è¿‘ä¼¼:
        p = 1.0 / (1.0 + np.exp(-logits))
        epsilon = 1e-9
        p = np.clip(p, epsilon, 1-epsilon)
        
        ll = np.sum(y * np.log(1-p) + (1-y) * np.log(p))
        return lp + ll

    n_walkers = max(32, 2 * n_dim)
    p0 = np.random.randn(n_walkers, n_dim) * 0.1
    
    sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_prob, args=(X, y_elim))
    sampler.run_mcmc(p0, 2000, progress=True)
    
    return sampler.get_chain(discard=500, flat=True)

rank_seasons = [1, 2] + list(range(28, 35))
mask_rank = df['season'].isin(rank_seasons)

samples_rank = run_better_mcmc(X_all[mask_rank], df[mask_rank]['actual_eliminate'].values, "Rank_Era")
samples_pct = run_better_mcmc(X_all[~mask_rank], df[~mask_rank]['actual_eliminate'].values, "Percent_Era")

# ===================== 5. ä»¿çœŸä¸å…·ä½“ç¥¨æ•°é¢„æµ‹ (å…³é”®ä¿®æ”¹) =====================
def simulate_votes_and_elimination(df, X_all, samples_rank, samples_pct, mask_rank):
    print("\nâš™ï¸ æ­£åœ¨è®¡ç®—ç²‰ä¸æŠ•ç¥¨åˆ†å¸ƒä¸æ·˜æ±°é¢„æµ‹...")
    
    beta_rank = samples_rank.mean(axis=0)
    beta_pct = samples_pct.mean(axis=0)
    
    # 1. è®¡ç®—æ½œåœ¨ç²‰ä¸åå¥½åˆ† (Log-Odds of Popularity)
    df['latent_popularity'] = 0.0
    df.loc[mask_rank, 'latent_popularity'] = np.dot(X_all[mask_rank], beta_rank)
    df.loc[~mask_rank, 'latent_popularity'] = np.dot(X_all[~mask_rank], beta_pct)
    
    # åˆå§‹åŒ–æ–°åˆ—
    df['pred_vote_share'] = 0.0 # é¢„æµ‹å¾—ç¥¨ç‡ (0-1)
    df['pred_fan_votes'] = 0    # é¢„æµ‹å…·ä½“ç¥¨æ•° (æ•´æ•°)
    df['est_eliminate'] = 0
    df['final_elim_prob'] = 0.0
    
    # 2. é€å‘¨è®¡ç®—ç¥¨æ•°åˆ†å¸ƒ
    # å‡è®¾ï¼šæ¯å­£åº¦çš„åŸºç¡€æŠ•ç¥¨æ± ä¸åŒï¼ˆæ—©æœŸå­£åº¦å¯èƒ½æ›´é«˜ï¼‰
    # è¿™é‡Œä½¿ç”¨è´¹ç±³ä¼°ç®—ï¼ˆFermi Estimationï¼‰ï¼šå‡è®¾å¹³å‡æ¯å‘¨æ€»ç¥¨æ•°åœ¨ 100ä¸‡ åˆ° 500ä¸‡ä¹‹é—´æ³¢åŠ¨
    
    for s in df['season'].unique():
        # ä¸ºè¯¥èµ›å­£è®¾å®šä¸€ä¸ªåŸºå‡†æµé‡ (æ¨¡æ‹Ÿæ”¶è§†ç‡æ³¢åŠ¨)
        season_base_vol = np.random.uniform(2e6, 5e6) # å‡è®¾ 200w-500w ç¥¨
        
        for w in df[df['season']==s]['week'].unique():
            idx = (df['season']==s) & (df['week']==w)
            if idx.sum() == 0: continue
            
            # A. æå–æœ¬å‘¨é€‰æ‰‹çš„æ½œåœ¨äººæ°”å€¼
            raw_logits = df.loc[idx, 'latent_popularity'].values
            
            # B. è®¡ç®—å¾—ç¥¨ç‡ (Softmax)
            # Softmax å°†ä»»æ„å®æ•°æ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œæ€»å’Œä¸º1
            # å¯ä»¥æ·»åŠ  temperature å‚æ•°è°ƒæ•´åˆ†å¸ƒçš„å¹³å¦ç¨‹åº¦ (temp > 1 æ›´å¹³å¦, temp < 1 æ›´å°–é”)
            temperature = 1.0 
            vote_shares = softmax(raw_logits / temperature)
            
            df.loc[idx, 'pred_vote_share'] = vote_shares
            
            # C. è®¡ç®—å…·ä½“ç¥¨æ•°
            # å‡è®¾å†³èµ›å‘¨ç¥¨æ•°æ›´å¤š
            week_factor = 1.0 + (w * 0.05) 
            total_week_votes = season_base_vol * week_factor * np.random.normal(1, 0.1)
            
            # åˆ†é…ç¥¨æ•°
            votes = (vote_shares * total_week_votes).astype(int)
            df.loc[idx, 'pred_fan_votes'] = votes
            
            # D. é¢„æµ‹æ·˜æ±° (ç»“åˆè¯„å§”åˆ†)
            # æ·˜æ±°æ¦‚ç‡ = 1 - P(Survival)
            # æ³¨æ„ï¼šlatent_popularity è¶Šé«˜ï¼Œç”Ÿå­˜ç‡è¶Šé«˜
            survival_prob = 1.0 / (1.0 + np.exp(-raw_logits))
            elim_prob = 1.0 - survival_prob
            
            # å½’ä¸€åŒ–æ·˜æ±°æ¦‚ç‡
            elim_prob_norm = softmax(elim_prob * 2) # æ”¾å¤§å·®å¼‚
            df.loc[idx, 'final_elim_prob'] = elim_prob_norm
            
            # åªæœ‰å½“å®é™…æœ‰æ·˜æ±°å‘ç”Ÿæ—¶ï¼Œæ‰æ ‡è®°é¢„æµ‹
            actual_elim_count = df.loc[idx, 'actual_eliminate'].sum()
            if actual_elim_count > 0:
                # é€‰å‡ºæ·˜æ±°æ¦‚ç‡æœ€é«˜çš„ N ä¸ªäºº (N=actual_elim_count)
                # è·å–è¯¥å‘¨å†…ç´¢å¼•
                week_indices = df[idx].index
                # æ’åºæ‰¾åˆ°æ¦‚ç‡æœ€å¤§çš„å‰Nä¸ª
                top_n_idx = np.argsort(elim_prob_norm)[-int(actual_elim_count):]
                
                # æ ‡è®°å…¨å±€ç´¢å¼•
                elim_global_idx = week_indices[top_n_idx]
                df.loc[elim_global_idx, 'est_eliminate'] = 1

    return df

df = simulate_votes_and_elimination(df, X_all, samples_rank, samples_pct, mask_rank)

# ===================== 6. ç»“æœå±•ç¤ºä¸éªŒè¯ =====================
def generate_report(df):
    valid_df = df[df['actual_eliminate'].isin([0, 1])]
    acc = accuracy_score(valid_df['actual_eliminate'], valid_df['est_eliminate'])
    
    print(f"\nğŸ“Š æ¨¡å‹æœ€ç»ˆæ€§èƒ½:")
    print(f"  - æ·˜æ±°é¢„æµ‹å‡†ç¡®ç‡: {acc:.2%}")
    
    # å±•ç¤ºéƒ¨åˆ†é¢„æµ‹çš„ç²‰ä¸ç¥¨æ•°
    print("\nğŸ« é¢„æµ‹ç²‰ä¸æŠ•ç¥¨æ ·æœ¬ (å‰10è¡Œ):")
    cols = ['season', 'week', 'player_id', 'industry', 'judge_score', 'pred_vote_share', 'pred_fan_votes', 'actual_eliminate']
    print(df[cols].head(10).to_string(index=False))
    
    # ç»Ÿè®¡æ¯ä¸€å‘¨æœ€é«˜ç¥¨æ•°å’Œæœ€ä½ç¥¨æ•°çš„å·®è·
    df['vote_gap'] = df.groupby(['season', 'week'])['pred_fan_votes'].transform(lambda x: x.max() - x.min())
    
    print("\nğŸ’° æŠ•ç¥¨æ•°æ®ç»Ÿè®¡:")
    print(f"  - å•å‘¨å¹³å‡æ€»ç¥¨æ•°: {df.groupby(['season', 'week'])['pred_fan_votes'].sum().mean():,.0f}")
    print(f"  - é€‰æ‰‹å¹³å‡å•å‘¨å¾—ç¥¨: {df['pred_fan_votes'].mean():,.0f}")
    
    # ç»˜å›¾ï¼šç²‰ä¸ç¥¨æ•°åˆ†å¸ƒ vs è¯„å§”åˆ†
    plt.figure(figsize=(15, 6))
    
    plt.subplot(1, 2, 1)
    sns.scatterplot(data=df, x='judge_score', y='pred_fan_votes', hue='actual_eliminate', alpha=0.6)
    plt.title("è¯„å§”åˆ†æ•° vs é¢„æµ‹ç²‰ä¸ç¥¨æ•° (é¢œè‰²=å®é™…æ·˜æ±°)")
    plt.xlabel("è¯„å§”åˆ†æ•°")
    plt.ylabel("é¢„æµ‹ç²‰ä¸ç¥¨æ•°")
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    # çœ‹ä¸€ä¸‹ä¸åŒè¡Œä¸šçš„å¹³å‡å¾—ç¥¨
    avg_vote_ind = df.groupby('industry')['pred_fan_votes'].mean().sort_values(ascending=False).head(10)
    sns.barplot(x=avg_vote_ind.values, y=avg_vote_ind.index, palette='viridis')
    plt.title("å„è¡Œä¸šé€‰æ‰‹å¹³å‡å•å‘¨å¾—ç¥¨æ•° (Top 10)")
    plt.xlabel("å¹³å‡ç¥¨æ•°")
    
    plt.tight_layout()
    plt.savefig('Task1_Fan_Votes_Analysis.png', dpi=300)
    print("\nâœ… å›¾è¡¨å·²ä¿å­˜: Task1_Fan_Votes_Analysis.png")
    
    # ä¿å­˜è¯¦ç»†Excel
    df.to_excel("Task1_Predicted_Fan_Votes.xlsx", index=False)
    print("âœ… è¯¦ç»†æ•°æ®å·²ä¿å­˜: Task1_Predicted_Fan_Votes.xlsx")

generate_report(df)